{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6468e0f4-17e0-4b78-83be-fdb3f011fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98394bbf-ab2e-46a9-87ab-b5784cf12c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/data.csv\")\n",
    "df_filtered = df[['agnostic', 'semantic']]\n",
    "\n",
    "agn_vocab_file = \"../agnostic_vocab.txt\"\n",
    "sem_vocab_file = \"../semantic_vocab.txt\"\n",
    "\n",
    "with open(agn_vocab_file, 'r') as file:\n",
    "    agn_vocab = file.read().splitlines()\n",
    "with open(sem_vocab_file, 'r') as file:\n",
    "    sem_vocab = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14958881-62df-455e-b5e3-98cfb6c748cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20020/1045124681.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_pre = df_filtered.applymap(lambda x: x.split('\\t')[0:-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 70142\n",
      "Validation size: 8768\n",
      "Test size: 8768\n"
     ]
    }
   ],
   "source": [
    "df_pre = df_filtered.applymap(lambda x: x.split('\\t')[0:-1])\n",
    "\n",
    "train_data, temp_data = train_test_split(df_pre, test_size=0.2, random_state=42)\n",
    "\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Validation size: {len(validation_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")\n",
    "\n",
    "def transform_row(row):\n",
    "    return {\n",
    "        'agnostic': ' '.join(row['agnostic']),  # Convert the list to a string\n",
    "        'semantic': ' '.join(row['semantic']),  # Convert the list to a string\n",
    "        'agnostic_tokens': ['<sos>'] + row['agnostic'] + ['<eos>'],  # Add <sos> and <eos>\n",
    "        'semantic_tokens': ['<sos>'] + row['semantic'] + ['<eos>']   # Add <sos> and <eos>\n",
    "    }\n",
    "\n",
    "train_data = train_data.apply(transform_row, axis=1).tolist()\n",
    "validation_data = validation_data.apply(transform_row, axis=1).tolist()\n",
    "test_data = test_data.apply(transform_row, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c470aa5b-6ee6-4994-aece-599c4bd27d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seeds for reproducibility\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a31ffc-d55b-4f7c-ba8a-eea2e2f0d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary creation\n",
    "class Vocabulary:\n",
    "    def __init__(self, tokens_list):\n",
    "        self.special_tokens = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "        self.token_to_index = {tok: idx for idx, tok in enumerate(self.special_tokens)}\n",
    "        self.index_to_token = {idx: tok for tok, idx in self.token_to_index.items()}\n",
    "        self.build_vocab(tokens_list)\n",
    "\n",
    "    def build_vocab(self, tokens_list):\n",
    "        for tokens in tokens_list:\n",
    "            for token in tokens:\n",
    "                if token not in self.token_to_index:\n",
    "                    idx = len(self.token_to_index)\n",
    "                    self.token_to_index[token] = idx\n",
    "                    self.index_to_token[idx] = token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def token_to_id(self, token):\n",
    "        return self.token_to_index.get(token, self.token_to_index['<unk>'])\n",
    "\n",
    "    def id_to_token(self, idx):\n",
    "        return self.index_to_token.get(idx, '<unk>')\n",
    "\n",
    "    def tokens_to_ids(self, tokens):\n",
    "        return [self.token_to_id(token) for token in tokens]\n",
    "\n",
    "    def ids_to_tokens(self, ids):\n",
    "        return [self.id_to_token(idx) for idx in ids]\n",
    "\n",
    "agnostic_vocab = Vocabulary([d['agnostic_tokens'] for d in train_data + validation_data + test_data])\n",
    "semantic_vocab = Vocabulary([d['semantic_tokens'] for d in train_data + validation_data + test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c5a9b4-4343-4915-8eb7-6e997c216055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, data, agnostic_vocab, semantic_vocab):\n",
    "        self.data = data\n",
    "        self.agnostic_vocab = agnostic_vocab\n",
    "        self.semantic_vocab = semantic_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        agnostic_tokens = self.data[idx]['agnostic_tokens']\n",
    "        semantic_tokens = self.data[idx]['semantic_tokens']\n",
    "        agnostic_ids = self.agnostic_vocab.tokens_to_ids(agnostic_tokens)\n",
    "        semantic_ids = self.semantic_vocab.tokens_to_ids(semantic_tokens)\n",
    "        return torch.tensor(agnostic_ids), torch.tensor(semantic_ids)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MusicDataset(train_data, agnostic_vocab, semantic_vocab)\n",
    "validation_dataset = MusicDataset(validation_data, agnostic_vocab, semantic_vocab)\n",
    "test_dataset = MusicDataset(test_data, agnostic_vocab, semantic_vocab)\n",
    "\n",
    "batch_size = 70\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f2bb30-890b-453e-b8c3-450c2cdda0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "429a130b-5e7b-43df-9b3e-65cb39274f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "input_dim = len(agnostic_vocab)\n",
    "output_dim = len(semantic_vocab)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = Encoder(input_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "decoder = Decoder(output_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=semantic_vocab.token_to_id('<pad>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5afb786-eb08-4d09-b8e1-76181993f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio=0.5):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src, trg = zip(*batch)\n",
    "        src = nn.utils.rnn.pad_sequence(src, padding_value=agnostic_vocab.token_to_id('<pad>')).to(device)\n",
    "        trg = nn.utils.rnn.pad_sequence(trg, padding_value=semantic_vocab.token_to_id('<pad>')).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f'Batch {i+1}/{len(data_loader)}: Loss {loss.item():.4f}', end='\\r')\n",
    "    print()  # Move to the next line after the epoch\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "# Validation function\n",
    "def validate_fn(model, data_loader, criterion, agnostic_vocab, semantic_vocab):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_sequences = 0\n",
    "    total_symbols = 0\n",
    "    incorrect_sequences = 0\n",
    "    incorrect_symbols = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            src, trg = zip(*batch)\n",
    "            src = nn.utils.rnn.pad_sequence(src, padding_value=agnostic_vocab.token_to_id('<pad>')).to(device)\n",
    "            trg = nn.utils.rnn.pad_sequence(trg, padding_value=semantic_vocab.token_to_id('<pad>')).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)  # No teacher forcing during validation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Convert predictions to token IDs\n",
    "            predicted_ids = output.argmax(dim=1).view(-1)\n",
    "            target_ids = trg.view(-1)\n",
    "            \n",
    "            # Calculate sequence-level errors\n",
    "            for pred_seq, true_seq in zip(\n",
    "                predicted_ids.split(trg.shape[0] // len(batch)),\n",
    "                target_ids.split(trg.shape[0] // len(batch))\n",
    "            ):\n",
    "                total_sequences += 1\n",
    "                total_symbols += len(true_seq)\n",
    "                if not torch.equal(pred_seq, true_seq):\n",
    "                    incorrect_sequences += 1\n",
    "                    incorrect_symbols += (pred_seq != true_seq).sum().item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader)\n",
    "    sequence_error_rate = incorrect_sequences / total_sequences\n",
    "    symbol_error_rate = incorrect_symbols / total_symbols\n",
    "\n",
    "    return avg_loss, sequence_error_rate, symbol_error_rate\n",
    "\n",
    "# Testing function\n",
    "def test_fn(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            src, trg = zip(*batch)\n",
    "            src = nn.utils.rnn.pad_sequence(src, padding_value=agnostic_vocab.token_to_id('<pad>')).to(device)\n",
    "            trg = nn.utils.rnn.pad_sequence(trg, padding_value=semantic_vocab.token_to_id('<pad>')).to(device)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)  # No teacher forcing during testing\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            predictions.append(output.argmax(-1))  # Store predicted tokens for analysis\n",
    "    return epoch_loss / len(data_loader), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abc6f0f-d50a-4124-8f20-9ae76f0fed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution loop\n",
    "def execute(model, train_loader, validation_loader, test_loader, optimizer, criterion, n_epochs, clip, teacher_forcing_ratio=0.5):\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(n_epochs):\n",
    "        teacher_forcing_ratio = max(0.5 * (1 - epoch / n_epochs), 0.1)\n",
    "        print(f'Epoch {epoch + 1}/{n_epochs}')\n",
    "        train_loss = train_fn(model, train_loader, optimizer, criterion, clip, teacher_forcing_ratio)\n",
    "        valid_loss, seq_er, sym_er = validate_fn(model, validation_loader, criterion, agnostic_vocab, semantic_vocab)\n",
    "        print(f'Training Loss: {train_loss:.4f} | Validation Loss: {valid_loss:.4f}')\n",
    "        print(f'Sequence error: {seq_er:.4f} | Symbol error {sym_er:.4f}')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')  # Save the best model\n",
    "            print('Model saved!')\n",
    "    # Load the best model and test\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    test_loss, predictions = test_fn(model, test_loader, criterion)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4a00d2-b202-43e8-82df-ce187a031ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Batch 1003/1003: Loss 2.7947\n",
      "Training Loss: 3.3866 | Validation Loss: 2.6564\n",
      "Sequence error: 0.9873 | Symbol error 0.8076\n",
      "Model saved!\n",
      "Epoch 2/100\n",
      "Batch 1003/1003: Loss 1.3695\n",
      "Training Loss: 2.1858 | Validation Loss: 1.9741\n",
      "Sequence error: 0.9691 | Symbol error 0.7360\n",
      "Model saved!\n",
      "Epoch 3/100\n",
      "Batch 1003/1003: Loss 1.9675\n",
      "Training Loss: 1.7202 | Validation Loss: 1.6514\n",
      "Sequence error: 0.9629 | Symbol error 0.6912\n",
      "Model saved!\n",
      "Epoch 4/100\n",
      "Batch 1003/1003: Loss 1.0888\n",
      "Training Loss: 1.4475 | Validation Loss: 1.4335\n",
      "Sequence error: 0.9605 | Symbol error 0.6624\n",
      "Model saved!\n",
      "Epoch 5/100\n",
      "Batch 1003/1003: Loss 0.9477\n",
      "Training Loss: 1.2601 | Validation Loss: 1.2422\n",
      "Sequence error: 0.9554 | Symbol error 0.6310\n",
      "Model saved!\n",
      "Epoch 6/100\n",
      "Batch 1003/1003: Loss 1.1677\n",
      "Training Loss: 1.1139 | Validation Loss: 1.1540\n",
      "Sequence error: 0.9560 | Symbol error 0.6176\n",
      "Model saved!\n",
      "Epoch 7/100\n",
      "Batch 1003/1003: Loss 2.5756\n",
      "Training Loss: 1.0029 | Validation Loss: 1.0353\n",
      "Sequence error: 0.9521 | Symbol error 0.5952\n",
      "Model saved!\n",
      "Epoch 8/100\n",
      "Batch 1003/1003: Loss 0.8941\n",
      "Training Loss: 0.9132 | Validation Loss: 0.9224\n",
      "Sequence error: 0.9505 | Symbol error 0.5756\n",
      "Model saved!\n",
      "Epoch 9/100\n",
      "Batch 1003/1003: Loss 0.8800\n",
      "Training Loss: 0.8381 | Validation Loss: 0.8520\n",
      "Sequence error: 0.9495 | Symbol error 0.5632\n",
      "Model saved!\n",
      "Epoch 10/100\n",
      "Batch 1003/1003: Loss 0.6441\n",
      "Training Loss: 0.7687 | Validation Loss: 0.7787\n",
      "Sequence error: 0.9481 | Symbol error 0.5497\n",
      "Model saved!\n",
      "Epoch 11/100\n",
      "Batch 1003/1003: Loss 0.5283\n",
      "Training Loss: 0.7146 | Validation Loss: 0.7377\n",
      "Sequence error: 0.9461 | Symbol error 0.5431\n",
      "Model saved!\n",
      "Epoch 12/100\n",
      "Batch 1003/1003: Loss 1.1187\n",
      "Training Loss: 0.6727 | Validation Loss: 0.7002\n",
      "Sequence error: 0.9457 | Symbol error 0.5360\n",
      "Model saved!\n",
      "Epoch 13/100\n",
      "Batch 1003/1003: Loss 0.6646\n",
      "Training Loss: 0.6245 | Validation Loss: 0.6301\n",
      "Sequence error: 0.9437 | Symbol error 0.5229\n",
      "Model saved!\n",
      "Epoch 14/100\n",
      "Batch 1003/1003: Loss 0.4396\n",
      "Training Loss: 0.5898 | Validation Loss: 0.6263\n",
      "Sequence error: 0.9435 | Symbol error 0.5226\n",
      "Model saved!\n",
      "Epoch 15/100\n",
      "Batch 1003/1003: Loss 0.6918\n",
      "Training Loss: 0.5607 | Validation Loss: 0.5828\n",
      "Sequence error: 0.9402 | Symbol error 0.5128\n",
      "Model saved!\n",
      "Epoch 16/100\n",
      "Batch 1003/1003: Loss 0.7349\n",
      "Training Loss: 0.5297 | Validation Loss: 0.5425\n",
      "Sequence error: 0.9397 | Symbol error 0.5063\n",
      "Model saved!\n",
      "Epoch 17/100\n",
      "Batch 1003/1003: Loss 0.2533\n",
      "Training Loss: 0.5044 | Validation Loss: 0.5224\n",
      "Sequence error: 0.9384 | Symbol error 0.5021\n",
      "Model saved!\n",
      "Epoch 18/100\n",
      "Batch 1003/1003: Loss 0.8560\n",
      "Training Loss: 0.4778 | Validation Loss: 0.5539\n",
      "Sequence error: 0.9401 | Symbol error 0.5076\n",
      "Epoch 19/100\n",
      "Batch 1003/1003: Loss 0.1760\n",
      "Training Loss: 0.4600 | Validation Loss: 0.5155\n",
      "Sequence error: 0.9356 | Symbol error 0.4999\n",
      "Model saved!\n",
      "Epoch 20/100\n",
      "Batch 1003/1003: Loss 0.2845\n",
      "Training Loss: 0.4417 | Validation Loss: 0.4914\n",
      "Sequence error: 0.9354 | Symbol error 0.4964\n",
      "Model saved!\n",
      "Epoch 21/100\n",
      "Batch 1003/1003: Loss 1.8400\n",
      "Training Loss: 0.4273 | Validation Loss: 0.4629\n",
      "Sequence error: 0.9316 | Symbol error 0.4911\n",
      "Model saved!\n",
      "Epoch 22/100\n",
      "Batch 1003/1003: Loss 0.4826\n",
      "Training Loss: 0.4217 | Validation Loss: 0.4481\n",
      "Sequence error: 0.9316 | Symbol error 0.4875\n",
      "Model saved!\n",
      "Epoch 23/100\n",
      "Batch 1003/1003: Loss 0.5038\n",
      "Training Loss: 0.3985 | Validation Loss: 0.4273\n",
      "Sequence error: 0.9277 | Symbol error 0.4839\n",
      "Model saved!\n",
      "Epoch 24/100\n",
      "Batch 1003/1003: Loss 0.5155\n",
      "Training Loss: 0.3853 | Validation Loss: 0.4443\n",
      "Sequence error: 0.9296 | Symbol error 0.4873\n",
      "Epoch 25/100\n",
      "Batch 1003/1003: Loss 0.3441\n",
      "Training Loss: 0.3729 | Validation Loss: 0.4231\n",
      "Sequence error: 0.9294 | Symbol error 0.4832\n",
      "Model saved!\n",
      "Epoch 26/100\n",
      "Batch 1003/1003: Loss 0.3881\n",
      "Training Loss: 0.3559 | Validation Loss: 0.4132\n",
      "Sequence error: 0.9289 | Symbol error 0.4803\n",
      "Model saved!\n",
      "Epoch 27/100\n",
      "Batch 1003/1003: Loss 0.0905\n",
      "Training Loss: 0.3488 | Validation Loss: 0.4019\n",
      "Sequence error: 0.9283 | Symbol error 0.4790\n",
      "Model saved!\n",
      "Epoch 28/100\n",
      "Batch 1003/1003: Loss 0.2186\n",
      "Training Loss: 0.3337 | Validation Loss: 0.3769\n",
      "Sequence error: 0.9259 | Symbol error 0.4742\n",
      "Model saved!\n",
      "Epoch 29/100\n",
      "Batch 1003/1003: Loss 0.4173\n",
      "Training Loss: 0.3265 | Validation Loss: 0.3980\n",
      "Sequence error: 0.9291 | Symbol error 0.4784\n",
      "Epoch 30/100\n",
      "Batch 1003/1003: Loss 0.2391\n",
      "Training Loss: 0.3151 | Validation Loss: 0.3885\n",
      "Sequence error: 0.9244 | Symbol error 0.4758\n",
      "Epoch 31/100\n",
      "Batch 1003/1003: Loss 0.4884\n",
      "Training Loss: 0.3121 | Validation Loss: 0.3625\n",
      "Sequence error: 0.9207 | Symbol error 0.4713\n",
      "Model saved!\n",
      "Epoch 32/100\n",
      "Batch 1003/1003: Loss 0.7762\n",
      "Training Loss: 0.3006 | Validation Loss: 0.3582\n",
      "Sequence error: 0.9219 | Symbol error 0.4702\n",
      "Model saved!\n",
      "Epoch 33/100\n",
      "Batch 1003/1003: Loss 0.0938\n",
      "Training Loss: 0.3013 | Validation Loss: 0.3687\n",
      "Sequence error: 0.9235 | Symbol error 0.4718\n",
      "Epoch 34/100\n",
      "Batch 1003/1003: Loss 0.2580\n",
      "Training Loss: 0.2877 | Validation Loss: 0.3403\n",
      "Sequence error: 0.9227 | Symbol error 0.4667\n",
      "Model saved!\n",
      "Epoch 35/100\n",
      "Batch 1003/1003: Loss 0.3974\n",
      "Training Loss: 0.2762 | Validation Loss: 0.3475\n",
      "Sequence error: 0.9227 | Symbol error 0.4677\n",
      "Epoch 36/100\n",
      "Batch 1003/1003: Loss 0.3501\n",
      "Training Loss: 0.2765 | Validation Loss: 0.3496\n",
      "Sequence error: 0.9229 | Symbol error 0.4681\n",
      "Epoch 37/100\n",
      "Batch 1003/1003: Loss 0.2695\n",
      "Training Loss: 0.2661 | Validation Loss: 0.3332\n",
      "Sequence error: 0.9151 | Symbol error 0.4651\n",
      "Model saved!\n",
      "Epoch 38/100\n",
      "Batch 1003/1003: Loss 0.4052\n",
      "Training Loss: 0.2683 | Validation Loss: 0.3292\n",
      "Sequence error: 0.9197 | Symbol error 0.4647\n",
      "Model saved!\n",
      "Epoch 39/100\n",
      "Batch 1003/1003: Loss 0.7727\n",
      "Training Loss: 0.2527 | Validation Loss: 0.3292\n",
      "Sequence error: 0.9204 | Symbol error 0.4646\n",
      "Epoch 40/100\n",
      "Batch 1003/1003: Loss 0.2230\n",
      "Training Loss: 0.2552 | Validation Loss: 0.3302\n",
      "Sequence error: 0.9167 | Symbol error 0.4635\n",
      "Epoch 41/100\n",
      "Batch 1003/1003: Loss 0.3565\n",
      "Training Loss: 0.2501 | Validation Loss: 0.3274\n",
      "Sequence error: 0.9195 | Symbol error 0.4641\n",
      "Model saved!\n",
      "Epoch 42/100\n",
      "Batch 1003/1003: Loss 0.3000\n",
      "Training Loss: 0.2466 | Validation Loss: 0.3175\n",
      "Sequence error: 0.9165 | Symbol error 0.4626\n",
      "Model saved!\n",
      "Epoch 43/100\n",
      "Batch 1003/1003: Loss 0.2207\n",
      "Training Loss: 0.2460 | Validation Loss: 0.3180\n",
      "Sequence error: 0.9178 | Symbol error 0.4619\n",
      "Epoch 44/100\n",
      "Batch 1003/1003: Loss 0.1246\n",
      "Training Loss: 0.2367 | Validation Loss: 0.3076\n",
      "Sequence error: 0.9150 | Symbol error 0.4601\n",
      "Model saved!\n",
      "Epoch 45/100\n",
      "Batch 1003/1003: Loss 0.3535\n",
      "Training Loss: 0.2277 | Validation Loss: 0.3046\n",
      "Sequence error: 0.9145 | Symbol error 0.4594\n",
      "Model saved!\n",
      "Epoch 46/100\n",
      "Batch 1003/1003: Loss 0.5469\n",
      "Training Loss: 0.2290 | Validation Loss: 0.3044\n",
      "Sequence error: 0.9141 | Symbol error 0.4594\n",
      "Model saved!\n",
      "Epoch 47/100\n",
      "Batch 1003/1003: Loss 0.3643\n",
      "Training Loss: 0.2242 | Validation Loss: 0.3036\n",
      "Sequence error: 0.9166 | Symbol error 0.4593\n",
      "Model saved!\n",
      "Epoch 48/100\n",
      "Batch 1003/1003: Loss 0.1432\n",
      "Training Loss: 0.2196 | Validation Loss: 0.3270\n",
      "Sequence error: 0.9183 | Symbol error 0.4643\n",
      "Epoch 49/100\n",
      "Batch 1003/1003: Loss 0.3797\n",
      "Training Loss: 0.2113 | Validation Loss: 0.2956\n",
      "Sequence error: 0.9167 | Symbol error 0.4579\n",
      "Model saved!\n",
      "Epoch 50/100\n",
      "Batch 1003/1003: Loss 0.0964\n",
      "Training Loss: 0.2099 | Validation Loss: 0.2890\n",
      "Sequence error: 0.9110 | Symbol error 0.4563\n",
      "Model saved!\n",
      "Epoch 51/100\n",
      "Batch 1003/1003: Loss 0.5736\n",
      "Training Loss: 0.2084 | Validation Loss: 0.3095\n",
      "Sequence error: 0.9159 | Symbol error 0.4600\n",
      "Epoch 52/100\n",
      "Batch 1003/1003: Loss 2.8762\n",
      "Training Loss: 0.2106 | Validation Loss: 0.3062\n",
      "Sequence error: 0.9164 | Symbol error 0.4587\n",
      "Epoch 53/100\n",
      "Batch 1003/1003: Loss 0.2549\n",
      "Training Loss: 0.1991 | Validation Loss: 0.3021\n",
      "Sequence error: 0.9153 | Symbol error 0.4584\n",
      "Epoch 54/100\n",
      "Batch 1003/1003: Loss 0.1565\n",
      "Training Loss: 0.2040 | Validation Loss: 0.3097\n",
      "Sequence error: 0.9166 | Symbol error 0.4603\n",
      "Epoch 55/100\n",
      "Batch 133/1003: Loss 0.2608\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m teacher_forcing_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Execute the training, validation, and testing process\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_forcing_ratio\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(model, train_loader, validation_loader, test_loader, optimizer, criterion, n_epochs, clip, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m      5\u001b[0m teacher_forcing_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m epoch \u001b[38;5;241m/\u001b[39m n_epochs), \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m valid_loss, seq_er, sym_er \u001b[38;5;241m=\u001b[39m validate_fn(model, validation_loader, criterion, agnostic_vocab, semantic_vocab)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     12\u001b[0m trg \u001b[38;5;241m=\u001b[39m trg[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 100\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "# Execute the training, validation, and testing process\n",
    "predictions = execute(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=validation_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    n_epochs=n_epochs,\n",
    "    clip=clip,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9e0178e-4a32-43a6-b34b-03e233d98c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_random_test_example(model, test_data, agnostic_vocab, semantic_vocab, max_len=50):\n",
    "    # Randomly select a test example\n",
    "    test_example = random.choice(test_data)\n",
    "    input_tokens = test_example['agnostic_tokens']\n",
    "    expected_output_tokens = test_example['semantic_tokens']\n",
    "    \n",
    "    \n",
    "    # Translate using the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Add <sos> and <eos> to the input string\n",
    "        input_tokens_with_sos_eos = [\"<sos>\"] + input_tokens + [\"<eos>\"]\n",
    "        input_ids = agnostic_vocab.tokens_to_ids(input_tokens_with_sos_eos)\n",
    "        input_tensor = torch.tensor(input_ids).unsqueeze(1).to(device)  # Add batch dimension\n",
    "\n",
    "        # Pass through the encoder\n",
    "        hidden, cell = model.encoder(input_tensor)\n",
    "\n",
    "        # Initialize the decoder with <sos> token\n",
    "        trg_indexes = [semantic_vocab.token_to_id('<sos>')]\n",
    "        for _ in range(max_len):\n",
    "            trg_tensor = torch.tensor([trg_indexes[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "            pred_token = output.argmax(1).item()\n",
    "            trg_indexes.append(pred_token)\n",
    "            if pred_token == semantic_vocab.token_to_id('<eos>'):\n",
    "                break\n",
    "\n",
    "        # Convert token IDs to tokens\n",
    "        output_tokens = semantic_vocab.ids_to_tokens(trg_indexes[1:-1])  # Exclude <sos> and <eos>\n",
    "\n",
    "    # Print input, expected output, and model's output\n",
    "    print(f\"Input String: {input_tokens}\\n\\n\")\n",
    "    print(f\"Expected Output: {expected_output_tokens}\\n\\n\")\n",
    "    print(f\"Model Output: {output_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef470303-d220-4bef-97ed-de5105a0fd87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String: ['<sos>', 'clef.G-L2', 'accidental.flat-L3', 'metersign.C/-L3', 'note.double_whole-L4', 'barline-L1', 'note.whole-S3', 'note.whole-S2', 'barline-L1', 'note.whole-L4', 'note.whole-L4', 'barline-L1', 'rest.half-L3', 'note.half-L5', 'dot-S5', 'note.quarter-S4', 'note.half-L4', 'slur.start-L4', 'barline-L1', 'slur.end-L4', 'note.quarter-L4', 'note.quarter-S3', 'note.half-L3', 'note.half-S2', '<eos>']\n",
      "\n",
      "\n",
      "Expected Output: ['<sos>', 'clef-G2', 'keySignature-FM', 'timeSignature-C/', 'note-D5_double_whole', 'barline', 'note-C5_whole', 'note-A4_whole', 'barline', 'note-D5_whole', 'note-D5_whole', 'barline', 'rest-half', 'note-F5_half.', 'note-E5_quarter', 'note-D5_half', 'tie', 'barline', 'note-D5_quarter', 'note-C5_quarter', 'note-Bb4_half', 'note-A4_half', '<eos>']\n",
      "\n",
      "\n",
      "Model Output: ['clef-G2', 'keySignature-FM', 'timeSignature-C/', 'note-Bb4_double_whole', 'barline', 'note-C5_whole', 'note-A4_whole', 'barline', 'note-D5_whole', 'note-D5_whole', 'barline', 'rest-half', 'note-F5_half.', 'note-E5_quarter', 'note-D5_half', 'tie', 'barline', 'barline', 'note-C5_quarter', 'note-Bb4_half', 'note-A4_quarter']\n"
     ]
    }
   ],
   "source": [
    "translate_random_test_example(model, test_data, agnostic_vocab, semantic_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1a1ed7e-27b0-4f54-815b-71b31d92df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b6643-eaac-417c-ba43-ff793aa950f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a3b60-d5b1-466c-9940-a83b52d90c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
